---
layout: post
title: "Study Note After Reading Chapter 9 of Realtime Rendering 4th"
description: "Record some concepts about PBR"
date: 2019-01-30
tags: [Note, RTR4]
comments: true
share: true
---

## Pre-requisites

### Solid Angle

In two dimensions, an angle of $2π$ radians covers the whole unit circle. Extending this to three dimensions, a solid angle of $4π$ steradians would cover the whole area of the unit sphere.
<center>
<img src="http://pm7bm4ebj.bkt.clouddn.com/rtr4_chap9_6.png" alt="Solid Angle" >
</center>

### Radiometry
<center>
<img src="http://pm7bm4ebj.bkt.clouddn.com/rtr4_chap9_7.png" alt="Radiometry" >
</center>

### Photometry

Radiometry deals purely with physical quantities, without taking account of human perception. A related field, photometry, is like radiometry, except that it weights everything by the sensitivity of the human eye. The results of radiometric computations are converted to photometric units by multiplying by the CIE photometric curve,1 a
bell-shaped curve centered around 555 nm that represents the eye’s response to various
wavelengths of light . Below is the photometric curve.
<center>
<img src="http://pm7bm4ebj.bkt.clouddn.com/rtr4_chap9_2.png" alt="Photometry" >
</center>

## Subsurface Scattering
<center>
<img src="http://pm7bm4ebj.bkt.clouddn.com/rtr4_chap9_1.png" alt="Scattering" >
</center>

This subsurface-scattered light exits the surface at varying distances from the entry point. The distribution of entry-exit distances depends on the density and properties of the scattering particles in the material. The relationship between these distances and the shading scale (the size of a pixel, or the distance between shading samples) is
important. If the entry-exit distances are small compared to the shading scale, they can be assumed to be effectively zero for shading purposes. This allows subsurface scattering to be combined with surface reflection into a local shading model, with outgoing light at a point depending only on incoming light at the same point.
Since subsurface-scattered light has a significantly different appearance than surface reflected light, it is convenient to divide them into separate shading terms. The specular term models surface reflection, and the diffuse term models local subsurface scattering.
If the entry-exit distances are large compared to the shading scale, then specialized rendering techniques, called global subsurface scattering techniques,  are needed to capture the visual effect of light entering the surface at one point and leaving it from another. 

## Bidrectional reflectance distribution function

The BRDF was defined by [Fred Nicodemus around 1965][1].

$$ f(l,v)=\frac{dL_{o}(v)}{dE_{i}(l)}=\frac{dL_{o}(v)}{L_{i}(l)(n\cdot l)dl} $$

We can now get the reflectance equation:

$$ L(v)=\int_{l\epsilon \Omega }^{ }f(l,v)L_{i}(l)(n\cdot l)dl $$

## Fresnel Reflectance
The Fresnel equations describe the dependence of $F$ on $θ_{i}$, $n_{1}$, and $n_{2}$. The value $n_{1}$ is the refractive index of the substance "above" the interface, where incident and reflected light propagate, and $n_{2}$ is the refractive index of the substance "below" the interface, where the refracted light propagates.

## Microgeometry
## Microfacet Theory
An important property of a microfacet model is the statistical distribution of the microfacet normals $m$.  This distribution is defined by the *surface’s normal distribution function*, or **NDF**. We will use $D(m)$ to refer to the **NDF** in equations.

Integrating $D(m)$ over the entire sphere of microfacet normals gives the area of the microsurface.

 $$\int_{m\epsilon \Theta }^{ }D(m)(n\cdot m)dm = 1$$

The integral is over the entire sphere, represented here by $\Theta$.
 More generally, the projections of the microsurface and macrosurface onto the plane perpendicular to any view direction $v$ are equal:

  $$\int_{m\epsilon \Theta }^{ }D(m)(v\cdot m)dm = v\cdot m$$

<center>
<img src="http://pm7bm4ebj.bkt.clouddn.com/rtr4_chap9_4.png" alt="Scattering" >
</center>
Most surfaces have **NDF**s that show a strong peak at the macroscopic surface normal $n$.
More generally, we always use an alternative way of relating the projected microfacet areas to the projected macrogeometry area: The sum of the projected areas of the visible microfacets is equal to the projected area of the macrosurface. 
To do that, we can define a masking function $G1(m, v)$, which gives the fraction of microfacets with normal $m$ that are visible along the view vector $v$.

$$\int_{m\epsilon \Theta }^{ }G_{1}(m,v)D(m)(v\cdot m)^{+}dm=v\cdot n$$

Dot product in the above equation is clamped to zero by the  $x^{+}$ notation.

Given a microgeometry description including a micro-BRDF $f_{\mu }(l, v, m)$, normal distribution function $D(m)$, and masking function $G_{1}(m, v)$, the overall macrosurface BRDF can be derived:

$$f(l,v)=\int_{m\epsilon \Omega }^{ }f_{\mu }(l,v,m)G_{2}(l,v,m)D(m)\frac{(m\cdot l)^{+}}{\left | n\cdot l \right |}\frac {(m\cdot v)^{+}}{\left | n\cdot v \right |}dm$$

This integral is over the hemisphere $\Omega$ centered on $n$. Instead of the masking function $G_{1}(m, v)$,  the equation uses the joint masking-shadowing function $G_{2}(l, v, m)$. It gives the fraction of microfacets with normal $m$ that are visible from two directions: the view vector $v$ and the light vector $l$.
<center>
<img src="http://pm7bm4ebj.bkt.clouddn.com/rtr4_chap9_3.png" alt="Scattering" >
</center>

[1]: https://www.osapublishing.org/ao/abstract.cfm?id=13818

